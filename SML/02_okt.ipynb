{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>11일</td>\n",
       "      <td>햇무리가 지고 관이 있었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>12일</td>\n",
       "      <td>홍문관 부제학 송세형 등이 차자를 올리기를, \"삼가 복상(卜相)하라는 본부를 보건...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>13일</td>\n",
       "      <td>홍언필을 의정부 영의정으로, 윤인경을 좌의정으로, 이기를 우의정으로, 성세창을 좌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>14일</td>\n",
       "      <td>정원이 서계(書啓)하기를, \"예문(禮文)에 ‘전하의 곡위(哭位)는 빈전(殯殿) 지게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>15일</td>\n",
       "      <td>정원이 아뢰기를, \"조종(祖宗)들은 모두 어용(御容)을 그렸는데 대행 대왕의 어용을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>6일</td>\n",
       "      <td>햇무리가 지고 관(冠)이 있었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>7일</td>\n",
       "      <td>전라도 남해현(南海縣)에 지진(地震)이 일어났다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>8일</td>\n",
       "      <td>자전(慈殿)이 정원에 전교하기를, \"요즈음 위에서 찬선(饌膳)을 드시는 것이 전만 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>9일</td>\n",
       "      <td>의원이 들어가 진찰하니, 심폐(心肺)와 비위(脾胃)의 맥이 미약하고 입술이 마르고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>10일</td>\n",
       "      <td>밤에 구름 같은 흑기(黑氣)가 동서로 가로질러 뻗쳐 있었다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label year month  day                                               text\n",
       "0       11   1년    1월  11일                                    햇무리가 지고 관이 있었다.\n",
       "1       11   1년    1월  12일   홍문관 부제학 송세형 등이 차자를 올리기를, \"삼가 복상(卜相)하라는 본부를 보건...\n",
       "2       11   1년    1월  13일   홍언필을 의정부 영의정으로, 윤인경을 좌의정으로, 이기를 우의정으로, 성세창을 좌...\n",
       "3       11   1년    1월  14일  정원이 서계(書啓)하기를, \"예문(禮文)에 ‘전하의 곡위(哭位)는 빈전(殯殿) 지게...\n",
       "4       11   1년    1월  15일  정원이 아뢰기를, \"조종(祖宗)들은 모두 어용(御容)을 그렸는데 대행 대왕의 어용을...\n",
       "..     ...  ...   ...  ...                                                ...\n",
       "202     11   1년   윤1월   6일                                 햇무리가 지고 관(冠)이 있었다.\n",
       "203     11   1년   윤1월   7일                        전라도 남해현(南海縣)에 지진(地震)이 일어났다.\n",
       "204     11   1년   윤1월   8일  자전(慈殿)이 정원에 전교하기를, \"요즈음 위에서 찬선(饌膳)을 드시는 것이 전만 ...\n",
       "205     11   1년   윤1월   9일  의원이 들어가 진찰하니, 심폐(心肺)와 비위(脾胃)의 맥이 미약하고 입술이 마르고 ...\n",
       "206     11   1년    1월  10일                  밤에 구름 같은 흑기(黑氣)가 동서로 가로질러 뻗쳐 있었다.\n",
       "\n",
       "[207 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kingtotal = pd.read_csv('josuncsv/king_11.csv', sep=';')\n",
    "kingtotal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# OKT 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# king00 DF의 Text 컬럼 전처리\n",
    "def okt_preprocess(text):\n",
    "    tokens = okt.pos(text)\n",
    "    filtered_words = [token[0] for token in tokens if not token[1] in ['Josa', 'Punctuation', 'Suffix', 'Unknown']] # Adjust filtering as needed \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "kingtotal['text_okt'] = kingtotal['text'].apply(okt_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>text</th>\n",
       "      <th>text_okt</th>\n",
       "      <th>text_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>11일</td>\n",
       "      <td>햇무리가 지고 관이 있었다.</td>\n",
       "      <td>햇무리 지고 관 있었다</td>\n",
       "      <td>[86, 207, 122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>12일</td>\n",
       "      <td>홍문관 부제학 송세형 등이 차자를 올리기를, \"삼가 복상(卜相)하라는 본부를 보건...</td>\n",
       "      <td>홍문관 부제학 송세형 등 차자 올 리기 삼가 복 卜相 하라 본부 보건 위 상신 相臣...</td>\n",
       "      <td>[209, 488, 574, 17, 261, 476, 485, 52, 1381, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>13일</td>\n",
       "      <td>홍언필을 의정부 영의정으로, 윤인경을 좌의정으로, 이기를 우의정으로, 성세창을 좌...</td>\n",
       "      <td>홍언필 의정부 영의정 윤인경 좌의정 이기 우의정 성 세창 좌찬성 이언 우찬성 허자 ...</td>\n",
       "      <td>[620, 511, 856, 81, 525, 377, 587, 104, 217, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>14일</td>\n",
       "      <td>정원이 서계(書啓)하기를, \"예문(禮文)에 ‘전하의 곡위(哭位)는 빈전(殯殿) 지게...</td>\n",
       "      <td>정원 서계 書啓 하기를 예문 禮文 ‘ 전하 곡위 哭位 는 빈전 殯殿 지게문 밖 동쪽...</td>\n",
       "      <td>[69, 255, 24, 462, 1114, 186, 300, 781, 189, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>15일</td>\n",
       "      <td>정원이 아뢰기를, \"조종(祖宗)들은 모두 어용(御容)을 그렸는데 대행 대왕의 어용을...</td>\n",
       "      <td>정원 아뢰 기를 조종 祖宗 들은 모두 어용 御容 그렸는데 대행 대왕 어용 평상시 그...</td>\n",
       "      <td>[69, 192, 43, 504, 75, 79, 504, 2925, 1443, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>6일</td>\n",
       "      <td>햇무리가 지고 관(冠)이 있었다.</td>\n",
       "      <td>햇무리 지고 관 冠 이 있었다</td>\n",
       "      <td>[86, 207, 122, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>7일</td>\n",
       "      <td>전라도 남해현(南海縣)에 지진(地震)이 일어났다.</td>\n",
       "      <td>전라도 남해 현 南海縣 지진 地震 이 일어났다</td>\n",
       "      <td>[1090, 1280, 933, 2787, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>8일</td>\n",
       "      <td>자전(慈殿)이 정원에 전교하기를, \"요즈음 위에서 찬선(饌膳)을 드시는 것이 전만 ...</td>\n",
       "      <td>자전 慈殿 이 정원 전교 하기를 요즈음 위 찬선 饌膳 드시는 것 전만 못 하여 들려...</td>\n",
       "      <td>[137, 3, 69, 46, 309, 21, 386, 2, 1588, 8, 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>윤1월</td>\n",
       "      <td>9일</td>\n",
       "      <td>의원이 들어가 진찰하니, 심폐(心肺)와 비위(脾胃)의 맥이 미약하고 입술이 마르고 ...</td>\n",
       "      <td>의원 들어가 진찰 하니 심폐 心肺 와 비위 脾胃 의 맥 미약 입술 마르고 낯빛 수척...</td>\n",
       "      <td>[172, 162, 10, 845, 277, 9, 271, 1349, 2650, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>1년</td>\n",
       "      <td>1월</td>\n",
       "      <td>10일</td>\n",
       "      <td>밤에 구름 같은 흑기(黑氣)가 동서로 가로질러 뻗쳐 있었다.</td>\n",
       "      <td>밤 구름 같은 흑 기 黑氣 가 동서로 가로질러 뻗쳐 있었다</td>\n",
       "      <td>[197, 959, 133, 991]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label year month  day                                               text  \\\n",
       "0       11   1년    1월  11일                                    햇무리가 지고 관이 있었다.   \n",
       "1       11   1년    1월  12일   홍문관 부제학 송세형 등이 차자를 올리기를, \"삼가 복상(卜相)하라는 본부를 보건...   \n",
       "2       11   1년    1월  13일   홍언필을 의정부 영의정으로, 윤인경을 좌의정으로, 이기를 우의정으로, 성세창을 좌...   \n",
       "3       11   1년    1월  14일  정원이 서계(書啓)하기를, \"예문(禮文)에 ‘전하의 곡위(哭位)는 빈전(殯殿) 지게...   \n",
       "4       11   1년    1월  15일  정원이 아뢰기를, \"조종(祖宗)들은 모두 어용(御容)을 그렸는데 대행 대왕의 어용을...   \n",
       "..     ...  ...   ...  ...                                                ...   \n",
       "202     11   1년   윤1월   6일                                 햇무리가 지고 관(冠)이 있었다.   \n",
       "203     11   1년   윤1월   7일                        전라도 남해현(南海縣)에 지진(地震)이 일어났다.   \n",
       "204     11   1년   윤1월   8일  자전(慈殿)이 정원에 전교하기를, \"요즈음 위에서 찬선(饌膳)을 드시는 것이 전만 ...   \n",
       "205     11   1년   윤1월   9일  의원이 들어가 진찰하니, 심폐(心肺)와 비위(脾胃)의 맥이 미약하고 입술이 마르고 ...   \n",
       "206     11   1년    1월  10일                  밤에 구름 같은 흑기(黑氣)가 동서로 가로질러 뻗쳐 있었다.   \n",
       "\n",
       "                                              text_okt  \\\n",
       "0                                         햇무리 지고 관 있었다   \n",
       "1    홍문관 부제학 송세형 등 차자 올 리기 삼가 복 卜相 하라 본부 보건 위 상신 相臣...   \n",
       "2    홍언필 의정부 영의정 윤인경 좌의정 이기 우의정 성 세창 좌찬성 이언 우찬성 허자 ...   \n",
       "3    정원 서계 書啓 하기를 예문 禮文 ‘ 전하 곡위 哭位 는 빈전 殯殿 지게문 밖 동쪽...   \n",
       "4    정원 아뢰 기를 조종 祖宗 들은 모두 어용 御容 그렸는데 대행 대왕 어용 평상시 그...   \n",
       "..                                                 ...   \n",
       "202                                   햇무리 지고 관 冠 이 있었다   \n",
       "203                          전라도 남해 현 南海縣 지진 地震 이 일어났다   \n",
       "204  자전 慈殿 이 정원 전교 하기를 요즈음 위 찬선 饌膳 드시는 것 전만 못 하여 들려...   \n",
       "205  의원 들어가 진찰 하니 심폐 心肺 와 비위 脾胃 의 맥 미약 입술 마르고 낯빛 수척...   \n",
       "206                   밤 구름 같은 흑 기 黑氣 가 동서로 가로질러 뻗쳐 있었다   \n",
       "\n",
       "                                          text_encoded  \n",
       "0                                       [86, 207, 122]  \n",
       "1    [209, 488, 574, 17, 261, 476, 485, 52, 1381, 3...  \n",
       "2    [620, 511, 856, 81, 525, 377, 587, 104, 217, 9...  \n",
       "3    [69, 255, 24, 462, 1114, 186, 300, 781, 189, 2...  \n",
       "4    [69, 192, 43, 504, 75, 79, 504, 2925, 1443, 17...  \n",
       "..                                                 ...  \n",
       "202                                  [86, 207, 122, 3]  \n",
       "203                         [1090, 1280, 933, 2787, 3]  \n",
       "204  [137, 3, 69, 46, 309, 21, 386, 2, 1588, 8, 19,...  \n",
       "205  [172, 162, 10, 845, 277, 9, 271, 1349, 2650, 2...  \n",
       "206                               [197, 959, 133, 991]  \n",
       "\n",
       "[207 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kingtotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label           0\n",
       "year            0\n",
       "month           0\n",
       "day             0\n",
       "text            0\n",
       "text_okt        0\n",
       "text_encoded    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kingtotal.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# OKT 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# king00 DF의 Text 컬럼 전처리\n",
    "def okt_preprocess(text):\n",
    "    tokens = okt.pos(text)\n",
    "    filtered_words = [token[0] for token in tokens if not token[1] in ['Josa', 'Punctuation', 'Suffix', 'Unknown']] # Adjust filtering as needed \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "kingtotal['text_okt'] = kingtotal['text'].apply(okt_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDF = kingtotal.label\n",
    "featureDF = kingtotal.text_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, y_train, y_test = train_test_split(featureDF,targetDF, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[209,\n",
       " 488,\n",
       " 574,\n",
       " 17,\n",
       " 261,\n",
       " 476,\n",
       " 485,\n",
       " 52,\n",
       " 1381,\n",
       " 334,\n",
       " 21,\n",
       " 2270,\n",
       " 9,\n",
       " 2294,\n",
       " 3,\n",
       " 2,\n",
       " 317,\n",
       " 1672,\n",
       " 33,\n",
       " 1683,\n",
       " 408,\n",
       " 279,\n",
       " 468,\n",
       " 1010,\n",
       " 352,\n",
       " 15,\n",
       " 224,\n",
       " 18,\n",
       " 458,\n",
       " 238,\n",
       " 160,\n",
       " 363,\n",
       " 40,\n",
       " 193,\n",
       " 32,\n",
       " 993,\n",
       " 32,\n",
       " 32,\n",
       " 2791,\n",
       " 1329,\n",
       " 2737,\n",
       " 225,\n",
       " 6,\n",
       " 355,\n",
       " 2,\n",
       " 44,\n",
       " 3,\n",
       " 25,\n",
       " 85,\n",
       " 899,\n",
       " 13,\n",
       " 71,\n",
       " 74,\n",
       " 132,\n",
       " 111,\n",
       " 230,\n",
       " 132,\n",
       " 218,\n",
       " 111,\n",
       " 230,\n",
       " 218,\n",
       " 2,\n",
       " 573,\n",
       " 9,\n",
       " 402,\n",
       " 74,\n",
       " 5,\n",
       " 40,\n",
       " 126,\n",
       " 583,\n",
       " 2698,\n",
       " 2,\n",
       " 2917,\n",
       " 886,\n",
       " 342,\n",
       " 184,\n",
       " 807,\n",
       " 268,\n",
       " 14,\n",
       " 832,\n",
       " 100,\n",
       " 2000,\n",
       " 90,\n",
       " 190,\n",
       " 996,\n",
       " 205,\n",
       " 943,\n",
       " 72,\n",
       " 340,\n",
       " 1855,\n",
       " 2,\n",
       " 2,\n",
       " 24,\n",
       " 71,\n",
       " 269,\n",
       " 74,\n",
       " 650,\n",
       " 468,\n",
       " 6,\n",
       " 355,\n",
       " 384,\n",
       " 10,\n",
       " 23,\n",
       " 26,\n",
       " 15,\n",
       " 337,\n",
       " 468,\n",
       " 2,\n",
       " 233,\n",
       " 485,\n",
       " 15,\n",
       " 177,\n",
       " 19,\n",
       " 100,\n",
       " 68,\n",
       " 16,\n",
       " 261,\n",
       " 1024,\n",
       " 58,\n",
       " 2,\n",
       " 190,\n",
       " 996,\n",
       " 90,\n",
       " 26,\n",
       " 39,\n",
       " 5,\n",
       " 1834,\n",
       " 33,\n",
       " 35,\n",
       " 2,\n",
       " 7,\n",
       " 26,\n",
       " 1724,\n",
       " 1389,\n",
       " 26,\n",
       " 356,\n",
       " 439]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureDF[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.concat([y_train, X_train], axis=1)\n",
    "testDF = pd.concat([y_test, x_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>11</td>\n",
       "      <td>[20, 220, 161, 17, 178, 302, 4, 130, 153, 321,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>11</td>\n",
       "      <td>[130, 812, 515, 9, 195, 48, 1804, 7, 1675, 18,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>11</td>\n",
       "      <td>[1408, 2137, 6, 1234, 193, 542, 891, 2, 3, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11</td>\n",
       "      <td>[148, 235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[1988, 512, 3, 520, 525, 81, 63, 10, 81, 101, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11</td>\n",
       "      <td>[86]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>[511, 822, 437, 1172, 75, 79, 2378, 6, 158, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11</td>\n",
       "      <td>[86]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>11</td>\n",
       "      <td>[210, 376, 1366, 4, 22, 4, 80, 108, 788, 1468,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>11</td>\n",
       "      <td>[2634, 1448, 1396, 465]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                       text_encoded\n",
       "146     11  [20, 220, 161, 17, 178, 302, 4, 130, 153, 321,...\n",
       "108     11  [130, 812, 515, 9, 195, 48, 1804, 7, 1675, 18,...\n",
       "176     11  [1408, 2137, 6, 1234, 193, 542, 891, 2, 3, 13,...\n",
       "31      11                                         [148, 235]\n",
       "12      11  [1988, 512, 3, 520, 525, 81, 63, 10, 81, 101, ...\n",
       "..     ...                                                ...\n",
       "106     11                                               [86]\n",
       "14      11  [511, 822, 437, 1172, 75, 79, 2378, 6, 158, 11...\n",
       "92      11                                               [86]\n",
       "179     11  [210, 376, 1366, 4, 22, 4, 80, 108, 788, 1468,...\n",
       "102     11                            [2634, 1448, 1396, 465]\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                                                          11\n",
      "text_encoded    [901, 1425, 656, 1565, 1755, 578, 1752, 69, 3,...\n",
      "char_count                                                   1312\n",
      "Name: 105, dtype: object\n"
     ]
    }
   ],
   "source": [
    "trainDF['char_count'] = trainDF['text_encoded'].str.len()\n",
    "\n",
    "max_char_row = trainDF.loc[trainDF['char_count'].idxmax()]\n",
    "\n",
    "print(max_char_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield iter(okt.nouns(text))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvalue = trainDF.values\n",
    "testvalue = testDF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'text_okt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9y/lpn0hjmn5csct06t4_r5qtjr0000gn/T/ipykernel_1423/2798692978.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_okt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Torch_NLP38/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'text_okt'"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(trainDF.text_okt), specials=[\"<pad>\", \"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1  # 0~3으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for label, text in batch:\n",
    "        label_list.append(label_pipeline(label))\n",
    "        processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class DLDataset(Dataset):\n",
    "    \n",
    "    # 초기화 함수\n",
    "    def __init__(self,x_data,y_data): # x_data : feature / y_data : target\n",
    "        super().__init__()\n",
    "        # x, y data => ndarray\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data\n",
    "        y_data = y_data.values if isinstance(y_data, pd.DataFrame) else y_data\n",
    "        \n",
    "        # ndarray => tensor : 텐서화\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)\n",
    "        \n",
    "    # 데이터셋의 갯수 체크 함수\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "        \n",
    "    \n",
    "    # 특정 인덱스 데이터 + 라벨 반환 콜백 함수 - 튜플로 반환\n",
    "    def __getitem__(self,index):\n",
    "        return self.feature[index],self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDLDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m, in \u001b[0;36mDLDataset.__init__\u001b[0;34m(self, x_data, y_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m y_data \u001b[38;5;241m=\u001b[39m y_data\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_data, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;28;01melse\u001b[39;00m y_data\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ndarray => tensor : 텐서화\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(y_data)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "my_dataset = DLDataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_iter\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch)\n\u001b[1;32m      3\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_iter, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_iter, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_iter, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([label \u001b[38;5;28;01mfor\u001b[39;00m (label, text) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_iter\u001b[49m]))\n\u001b[1;32m      2\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab)\n\u001b[1;32m      3\u001b[0m embed_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 300\n",
    "num_epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "print(f\"num_class : {num_class}    vocab_size : {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_vocab,\n",
    "        hidden_dim,\n",
    "        embedding_dim,\n",
    "        n_layer,\n",
    "        dropout=0.5,\n",
    "        bidirectional=True,\n",
    "        model_type=\"lstm\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab, embedding_dim=embedding_dim, padding_idx=0\n",
    "        )\n",
    "        if model_type == \"rnn\":\n",
    "            self.model = nn.RNN(\n",
    "                input_size=embedding_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                num_layers=n_layer,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        elif model_type == \"lstm\":\n",
    "            self.model = nn.LSTM(\n",
    "                input_size=embedding_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                num_layers=n_layer,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "\n",
    "        if bidirectional:\n",
    "            self.classifier = nn.Linear(hidden_dim * 2, num_class)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        output, _ = self.model(embeddings)\n",
    "        last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        logits = self.classifier(last_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(vocab)\n",
    "hidden_dim = 64\n",
    "embedding_dim = 128\n",
    "n_layer = 2\n",
    "\n",
    "classifier = SentenceClassifier(\n",
    "    n_vocab=n_vocab, \n",
    "    hidden_dim=hidden_dim, \n",
    "    embedding_dim=embedding_dim, \n",
    "    n_layer=n_layer\n",
    ").to(device)\n",
    "\n",
    "classifier = TextClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_class=num_class\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for idx, (labels, texts, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts, offsets)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        acc = (outputs.argmax(1) == labels).float().sum()\n",
    "        total_acc += acc.item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    return total_loss / total_samples, total_acc / total_samples\n",
    "\n",
    "def evaluate(model, dataloader, is_training=False):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for labels, texts, offsets in dataloader:\n",
    "            outputs = model(texts, offsets)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            acc = (outputs.argmax(1) == labels).float().sum()\n",
    "            total_acc += acc.item()\n",
    "            total_samples += labels.size(0)\n",
    "    return total_loss / total_samples, total_acc / total_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n",
    "        text = text.unsqueeze(0)\n",
    "        offsets = torch.tensor([0]).to(device)\n",
    "        predicted_label = model(text, offsets)\n",
    "        return predicted_label.argmax(1).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(classifier, train_loader)\n",
    "    valid_loss, valid_acc = evaluate(classifier, test_loader)  # valid_loader 대신 test_loader 사용\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(classifier.state_dict(), 'best_model.pth')\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "classifier.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss, test_acc = evaluate(classifier, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
