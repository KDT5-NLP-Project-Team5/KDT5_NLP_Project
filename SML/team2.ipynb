{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "pattern = re.compile(r'.*일')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wang = [chr(i) for i in range(ord('a'), ord('y')+1)]\n",
    "mainsub = ['a','b']\n",
    "jaewi = [f\"{x:02d}\" for x in range(0, 54)]\n",
    "month = [f\"{x:02d}\" for x in range(0, 13)]\n",
    "yoondal = [0, 1]\n",
    "day = [f\"{x:02d}\" for x in range(0, 34)]\n",
    "page = [f\"{x:03d}\" for x in range(1, 200)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for w in wang:\n",
    "    for m in mainsub:\n",
    "        for j in jaewi:\n",
    "            for m2 in month:\n",
    "                for y in yoondal:\n",
    "                    for d in day:\n",
    "                        for p in page:\n",
    "\n",
    "                            # url = f'https://sillok.history.go.kr/id/kaa_10107017_001'\n",
    "                            url = f\"https://sillok.history.go.kr/id/k{w}{m}\"+'_1'+f\"{j}{m2}{y}{d}\"+'_'+f\"{p}\"\n",
    "\n",
    "                            \n",
    "                            response = requests.get(url, verify=False)\n",
    "                            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "                            links = soup.find_all(\"div\")\n",
    "\n",
    "                            content_div = soup.find('div', {'class': 'ins_view_pd'})\n",
    "\n",
    "                            subtitle = soup.find('span', {'class': 'tit_loc'})\n",
    "\n",
    "                            subtitle = subtitle.get_text()\n",
    "\n",
    "                            subtitle = subtitle.split(' ')[2:6]\n",
    "                            subtitle = ' '.join(subtitle)\n",
    "\n",
    "                            txt = content_div.text\n",
    "                            with open(f'txtt/{subtitle}.txt', 'w', encoding='utf-8-sig') as f:\n",
    "                                f.write(txt)\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sml/anaconda3/envs/Torch_NLP38/lib/python3.8/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'sillok.history.go.kr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m content_div \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mins_view_pd\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     33\u001b[0m subtitle \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtit_loc\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m---> 35\u001b[0m subtitle \u001b[38;5;241m=\u001b[39m \u001b[43msubtitle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m()\n\u001b[1;32m     36\u001b[0m subtitle \u001b[38;5;241m=\u001b[39m subtitle\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m     37\u001b[0m subtitle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(subtitle)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "\n",
    "# pattern = re.compile(r'.\\*일')\n",
    "\n",
    "# wang = [chr(i) for i in range(ord('a'), ord('y')+1)]\n",
    "# mainsub = ['a', 'b']\n",
    "# jaewi = [f\"{x:02d}\" for x in range(0, 54)]\n",
    "# month = [f\"{x:02d}\" for x in range(0, 13)]\n",
    "# yoondal = [0, 1]\n",
    "# day = [f\"{x:02d}\" for x in range(0, 34)]\n",
    "# page = [f\"{x:03d}\" for x in range(1, 200)]\n",
    "\n",
    "# for w in wang:\n",
    "#     for m in mainsub:\n",
    "#         for j in jaewi:\n",
    "#             for m2 in month:\n",
    "#                 for y in yoondal:\n",
    "#                     for d in day:\n",
    "#                         for p in page:\n",
    "#                             # Skip the combination where d is '00' and p is '001'\n",
    "#                             if d == '00' and p == '001':\n",
    "#                                 continue\n",
    "\n",
    "#                             url = f\"https://sillok.history.go.kr/id/k{w}{m}\"+'_1'+f\"{j}{m2}{y}{d}\"+'_'+f\"{p}\"\n",
    "\n",
    "#                             response = requests.get(url, verify=False)\n",
    "#                             soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#                             links = soup.find_all(\"div\")\n",
    "#                             content_div = soup.find('div', {'class': 'ins_view_pd'})\n",
    "#                             subtitle = soup.find('span', {'class': 'tit_loc'})\n",
    "\n",
    "#                             subtitle = subtitle.get_text()\n",
    "#                             subtitle = subtitle.split(' ')[2:6]\n",
    "#                             subtitle = ' '.join(subtitle)\n",
    "#                             txt = content_div.text\n",
    "\n",
    "#                             with open(f'txtt/{subtitle}.txt', 'w', encoding='utf-8-sig') as f:\n",
    "#                                 f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
